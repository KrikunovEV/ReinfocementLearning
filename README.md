# ReinforcementLearning

Here You can see the progress of my **Graduate work**.

### Papers and links:
1. The main [StarCraft II: A New Challenge for Reinforcement Learning](https://arxiv.org/pdf/1708.04782.pdf)
2. A3C network [Asynchronous Actor-Critic Agents](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2)
3. VIN [Value Iteration Network](http://papers.nips.cc/paper/6046-value-iteration-networks.pdf)

Additionally:

4. Environments for classic control from [GYM](https://github.com/openai/gym/wiki/Leaderboard)
5. All environments from [GYM](https://gym.openai.com/envs/#classic_control)
6. API for Starcraft 2 - [PySC2](https://github.com/deepmind/pysc2)
7. Detailed information about PySC is [here](https://github.com/deepmind/pysc2/blob/master/docs/environment.md)
7. In this work authors propose multi-threaded asynchronous variants of one-step Sarsa, one-step Q-learning, n-step Q-learning, and
advantage actor-critic using multiple CPU threads on a single machine instead of separate machines.  [Asynchronous Methods for Deep RL](https://arxiv.org/pdf/1602.01783.pdf#page=9)
